{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from vgg16 import _Vgg16, Block\n",
    "from trainer.trainer_kfold import TrainerWithKFoldValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_16_adam = _Vgg16(Block, [2, 2, 3, 3, 3])\n",
    "optimizer_adam = optim.Adam(vgg_16_adam.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 64, 32, 32]          --\n",
      "|    └─Block: 2-1                        [-1, 64, 64, 64]          --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 64, 64, 64]          1,792\n",
      "|    |    └─BatchNorm2d: 3-2             [-1, 64, 64, 64]          128\n",
      "|    |    └─ReLU: 3-3                    [-1, 64, 64, 64]          --\n",
      "|    └─Block: 2-2                        [-1, 64, 64, 64]          --\n",
      "|    |    └─Conv2d: 3-4                  [-1, 64, 64, 64]          36,928\n",
      "|    |    └─BatchNorm2d: 3-5             [-1, 64, 64, 64]          128\n",
      "|    |    └─ReLU: 3-6                    [-1, 64, 64, 64]          --\n",
      "|    └─MaxPool2d: 2-3                    [-1, 64, 32, 32]          --\n",
      "├─Sequential: 1-2                        [-1, 128, 16, 16]         --\n",
      "|    └─Block: 2-4                        [-1, 128, 32, 32]         --\n",
      "|    |    └─Conv2d: 3-7                  [-1, 128, 32, 32]         73,856\n",
      "|    |    └─BatchNorm2d: 3-8             [-1, 128, 32, 32]         256\n",
      "|    |    └─ReLU: 3-9                    [-1, 128, 32, 32]         --\n",
      "|    └─Block: 2-5                        [-1, 128, 32, 32]         --\n",
      "|    |    └─Conv2d: 3-10                 [-1, 128, 32, 32]         147,584\n",
      "|    |    └─BatchNorm2d: 3-11            [-1, 128, 32, 32]         256\n",
      "|    |    └─ReLU: 3-12                   [-1, 128, 32, 32]         --\n",
      "|    └─MaxPool2d: 2-6                    [-1, 128, 16, 16]         --\n",
      "├─Sequential: 1-3                        [-1, 256, 8, 8]           --\n",
      "|    └─Block: 2-7                        [-1, 256, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-13                 [-1, 256, 16, 16]         295,168\n",
      "|    |    └─BatchNorm2d: 3-14            [-1, 256, 16, 16]         512\n",
      "|    |    └─ReLU: 3-15                   [-1, 256, 16, 16]         --\n",
      "|    └─Block: 2-8                        [-1, 256, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-16                 [-1, 256, 16, 16]         590,080\n",
      "|    |    └─BatchNorm2d: 3-17            [-1, 256, 16, 16]         512\n",
      "|    |    └─ReLU: 3-18                   [-1, 256, 16, 16]         --\n",
      "|    └─Block: 2-9                        [-1, 256, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-19                 [-1, 256, 16, 16]         590,080\n",
      "|    |    └─BatchNorm2d: 3-20            [-1, 256, 16, 16]         512\n",
      "|    |    └─ReLU: 3-21                   [-1, 256, 16, 16]         --\n",
      "|    └─MaxPool2d: 2-10                   [-1, 256, 8, 8]           --\n",
      "├─Sequential: 1-4                        [-1, 512, 4, 4]           --\n",
      "|    └─Block: 2-11                       [-1, 512, 8, 8]           --\n",
      "|    |    └─Conv2d: 3-22                 [-1, 512, 8, 8]           1,180,160\n",
      "|    |    └─BatchNorm2d: 3-23            [-1, 512, 8, 8]           1,024\n",
      "|    |    └─ReLU: 3-24                   [-1, 512, 8, 8]           --\n",
      "|    └─Block: 2-12                       [-1, 512, 8, 8]           --\n",
      "|    |    └─Conv2d: 3-25                 [-1, 512, 8, 8]           2,359,808\n",
      "|    |    └─BatchNorm2d: 3-26            [-1, 512, 8, 8]           1,024\n",
      "|    |    └─ReLU: 3-27                   [-1, 512, 8, 8]           --\n",
      "|    └─Block: 2-13                       [-1, 512, 8, 8]           --\n",
      "|    |    └─Conv2d: 3-28                 [-1, 512, 8, 8]           2,359,808\n",
      "|    |    └─BatchNorm2d: 3-29            [-1, 512, 8, 8]           1,024\n",
      "|    |    └─ReLU: 3-30                   [-1, 512, 8, 8]           --\n",
      "|    └─MaxPool2d: 2-14                   [-1, 512, 4, 4]           --\n",
      "├─Sequential: 1-5                        [-1, 512, 2, 2]           --\n",
      "|    └─Block: 2-15                       [-1, 512, 4, 4]           --\n",
      "|    |    └─Conv2d: 3-31                 [-1, 512, 4, 4]           2,359,808\n",
      "|    |    └─BatchNorm2d: 3-32            [-1, 512, 4, 4]           1,024\n",
      "|    |    └─ReLU: 3-33                   [-1, 512, 4, 4]           --\n",
      "|    └─Block: 2-16                       [-1, 512, 4, 4]           --\n",
      "|    |    └─Conv2d: 3-34                 [-1, 512, 4, 4]           2,359,808\n",
      "|    |    └─BatchNorm2d: 3-35            [-1, 512, 4, 4]           1,024\n",
      "|    |    └─ReLU: 3-36                   [-1, 512, 4, 4]           --\n",
      "|    └─Block: 2-17                       [-1, 512, 4, 4]           --\n",
      "|    |    └─Conv2d: 3-37                 [-1, 512, 4, 4]           2,359,808\n",
      "|    |    └─BatchNorm2d: 3-38            [-1, 512, 4, 4]           1,024\n",
      "|    |    └─ReLU: 3-39                   [-1, 512, 4, 4]           --\n",
      "|    └─MaxPool2d: 2-18                   [-1, 512, 2, 2]           --\n",
      "├─AdaptiveAvgPool2d: 1-6                 [-1, 512, 1, 1]           --\n",
      "├─Flatten: 1-7                           [-1, 512]                 --\n",
      "├─Sequential: 1-8                        [-1, 4096]                --\n",
      "|    └─Linear: 2-19                      [-1, 4096]                2,101,248\n",
      "|    └─ReLU: 2-20                        [-1, 4096]                --\n",
      "|    └─Dropout: 2-21                     [-1, 4096]                --\n",
      "├─Sequential: 1-9                        [-1, 4096]                --\n",
      "|    └─Linear: 2-22                      [-1, 4096]                16,781,312\n",
      "|    └─ReLU: 2-23                        [-1, 4096]                --\n",
      "|    └─Dropout: 2-24                     [-1, 4096]                --\n",
      "├─Linear: 1-10                           [-1, 10]                  40,970\n",
      "==========================================================================================\n",
      "Total params: 33,646,666\n",
      "Trainable params: 33,646,666\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 1.32\n",
      "==========================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 16.94\n",
      "Params size (MB): 128.35\n",
      "Estimated Total Size (MB): 145.34\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 64, 32, 32]          --\n",
       "|    └─Block: 2-1                        [-1, 64, 64, 64]          --\n",
       "|    |    └─Conv2d: 3-1                  [-1, 64, 64, 64]          1,792\n",
       "|    |    └─BatchNorm2d: 3-2             [-1, 64, 64, 64]          128\n",
       "|    |    └─ReLU: 3-3                    [-1, 64, 64, 64]          --\n",
       "|    └─Block: 2-2                        [-1, 64, 64, 64]          --\n",
       "|    |    └─Conv2d: 3-4                  [-1, 64, 64, 64]          36,928\n",
       "|    |    └─BatchNorm2d: 3-5             [-1, 64, 64, 64]          128\n",
       "|    |    └─ReLU: 3-6                    [-1, 64, 64, 64]          --\n",
       "|    └─MaxPool2d: 2-3                    [-1, 64, 32, 32]          --\n",
       "├─Sequential: 1-2                        [-1, 128, 16, 16]         --\n",
       "|    └─Block: 2-4                        [-1, 128, 32, 32]         --\n",
       "|    |    └─Conv2d: 3-7                  [-1, 128, 32, 32]         73,856\n",
       "|    |    └─BatchNorm2d: 3-8             [-1, 128, 32, 32]         256\n",
       "|    |    └─ReLU: 3-9                    [-1, 128, 32, 32]         --\n",
       "|    └─Block: 2-5                        [-1, 128, 32, 32]         --\n",
       "|    |    └─Conv2d: 3-10                 [-1, 128, 32, 32]         147,584\n",
       "|    |    └─BatchNorm2d: 3-11            [-1, 128, 32, 32]         256\n",
       "|    |    └─ReLU: 3-12                   [-1, 128, 32, 32]         --\n",
       "|    └─MaxPool2d: 2-6                    [-1, 128, 16, 16]         --\n",
       "├─Sequential: 1-3                        [-1, 256, 8, 8]           --\n",
       "|    └─Block: 2-7                        [-1, 256, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-13                 [-1, 256, 16, 16]         295,168\n",
       "|    |    └─BatchNorm2d: 3-14            [-1, 256, 16, 16]         512\n",
       "|    |    └─ReLU: 3-15                   [-1, 256, 16, 16]         --\n",
       "|    └─Block: 2-8                        [-1, 256, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-16                 [-1, 256, 16, 16]         590,080\n",
       "|    |    └─BatchNorm2d: 3-17            [-1, 256, 16, 16]         512\n",
       "|    |    └─ReLU: 3-18                   [-1, 256, 16, 16]         --\n",
       "|    └─Block: 2-9                        [-1, 256, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-19                 [-1, 256, 16, 16]         590,080\n",
       "|    |    └─BatchNorm2d: 3-20            [-1, 256, 16, 16]         512\n",
       "|    |    └─ReLU: 3-21                   [-1, 256, 16, 16]         --\n",
       "|    └─MaxPool2d: 2-10                   [-1, 256, 8, 8]           --\n",
       "├─Sequential: 1-4                        [-1, 512, 4, 4]           --\n",
       "|    └─Block: 2-11                       [-1, 512, 8, 8]           --\n",
       "|    |    └─Conv2d: 3-22                 [-1, 512, 8, 8]           1,180,160\n",
       "|    |    └─BatchNorm2d: 3-23            [-1, 512, 8, 8]           1,024\n",
       "|    |    └─ReLU: 3-24                   [-1, 512, 8, 8]           --\n",
       "|    └─Block: 2-12                       [-1, 512, 8, 8]           --\n",
       "|    |    └─Conv2d: 3-25                 [-1, 512, 8, 8]           2,359,808\n",
       "|    |    └─BatchNorm2d: 3-26            [-1, 512, 8, 8]           1,024\n",
       "|    |    └─ReLU: 3-27                   [-1, 512, 8, 8]           --\n",
       "|    └─Block: 2-13                       [-1, 512, 8, 8]           --\n",
       "|    |    └─Conv2d: 3-28                 [-1, 512, 8, 8]           2,359,808\n",
       "|    |    └─BatchNorm2d: 3-29            [-1, 512, 8, 8]           1,024\n",
       "|    |    └─ReLU: 3-30                   [-1, 512, 8, 8]           --\n",
       "|    └─MaxPool2d: 2-14                   [-1, 512, 4, 4]           --\n",
       "├─Sequential: 1-5                        [-1, 512, 2, 2]           --\n",
       "|    └─Block: 2-15                       [-1, 512, 4, 4]           --\n",
       "|    |    └─Conv2d: 3-31                 [-1, 512, 4, 4]           2,359,808\n",
       "|    |    └─BatchNorm2d: 3-32            [-1, 512, 4, 4]           1,024\n",
       "|    |    └─ReLU: 3-33                   [-1, 512, 4, 4]           --\n",
       "|    └─Block: 2-16                       [-1, 512, 4, 4]           --\n",
       "|    |    └─Conv2d: 3-34                 [-1, 512, 4, 4]           2,359,808\n",
       "|    |    └─BatchNorm2d: 3-35            [-1, 512, 4, 4]           1,024\n",
       "|    |    └─ReLU: 3-36                   [-1, 512, 4, 4]           --\n",
       "|    └─Block: 2-17                       [-1, 512, 4, 4]           --\n",
       "|    |    └─Conv2d: 3-37                 [-1, 512, 4, 4]           2,359,808\n",
       "|    |    └─BatchNorm2d: 3-38            [-1, 512, 4, 4]           1,024\n",
       "|    |    └─ReLU: 3-39                   [-1, 512, 4, 4]           --\n",
       "|    └─MaxPool2d: 2-18                   [-1, 512, 2, 2]           --\n",
       "├─AdaptiveAvgPool2d: 1-6                 [-1, 512, 1, 1]           --\n",
       "├─Flatten: 1-7                           [-1, 512]                 --\n",
       "├─Sequential: 1-8                        [-1, 4096]                --\n",
       "|    └─Linear: 2-19                      [-1, 4096]                2,101,248\n",
       "|    └─ReLU: 2-20                        [-1, 4096]                --\n",
       "|    └─Dropout: 2-21                     [-1, 4096]                --\n",
       "├─Sequential: 1-9                        [-1, 4096]                --\n",
       "|    └─Linear: 2-22                      [-1, 4096]                16,781,312\n",
       "|    └─ReLU: 2-23                        [-1, 4096]                --\n",
       "|    └─Dropout: 2-24                     [-1, 4096]                --\n",
       "├─Linear: 1-10                           [-1, 10]                  40,970\n",
       "==========================================================================================\n",
       "Total params: 33,646,666\n",
       "Trainable params: 33,646,666\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.32\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 16.94\n",
       "Params size (MB): 128.35\n",
       "Estimated Total Size (MB): 145.34\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(vgg_16_adam, (3, 64, 64), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TrainerWithKFoldValidation(vgg_16_adam, optimizer_adam, trainset, testset, save_name=\"vgg16_adam_batch32_fold5\", path=None, epoch=EPOCH, batch=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch=  1, batch_cnt=  250] loss: 2.24277\n",
      "Train Acc: 17 %\n",
      "Accuracy: 16 %\n",
      "[epoch=  1, batch_cnt=  500] loss: 2.02221\n",
      "Train Acc: 20 %\n",
      "Accuracy: 20 %\n",
      "[epoch=  1, batch_cnt=  750] loss: 1.95849\n",
      "Train Acc: 23 %\n",
      "Accuracy: 23 %\n",
      "[epoch=  1, batch_cnt= 1000] loss: 1.90515\n",
      "Train Acc: 23 %\n",
      "Accuracy: 22 %\n",
      "[epoch=  1, batch_cnt= 1250] loss: 1.85601\n",
      "Train Acc: 26 %\n",
      "Accuracy: 26 %\n",
      "[epoch=  2, batch_cnt=  250] loss: 1.79100\n",
      "Train Acc: 26 %\n",
      "Accuracy: 26 %\n",
      "[epoch=  2, batch_cnt=  500] loss: 1.78660\n",
      "Train Acc: 27 %\n",
      "Accuracy: 27 %\n",
      "[epoch=  2, batch_cnt=  750] loss: 1.73980\n",
      "Train Acc: 29 %\n",
      "Accuracy: 29 %\n",
      "[epoch=  2, batch_cnt= 1000] loss: 1.73608\n",
      "Train Acc: 30 %\n",
      "Accuracy: 30 %\n",
      "[epoch=  2, batch_cnt= 1250] loss: 1.68148\n",
      "Train Acc: 31 %\n",
      "Accuracy: 32 %\n",
      "[epoch=  3, batch_cnt=  250] loss: 1.66655\n",
      "Train Acc: 33 %\n",
      "Accuracy: 33 %\n",
      "[epoch=  3, batch_cnt=  500] loss: 1.63592\n",
      "Train Acc: 36 %\n",
      "Accuracy: 37 %\n",
      "[epoch=  3, batch_cnt=  750] loss: 1.60156\n",
      "Train Acc: 38 %\n",
      "Accuracy: 38 %\n",
      "[epoch=  3, batch_cnt= 1000] loss: 1.56933\n",
      "Train Acc: 39 %\n",
      "Accuracy: 39 %\n",
      "[epoch=  3, batch_cnt= 1250] loss: 1.55885\n",
      "Train Acc: 39 %\n",
      "Accuracy: 40 %\n",
      "[epoch=  4, batch_cnt=  250] loss: 1.50603\n",
      "Train Acc: 42 %\n",
      "Accuracy: 41 %\n",
      "[epoch=  4, batch_cnt=  500] loss: 1.47910\n",
      "Train Acc: 46 %\n",
      "Accuracy: 46 %\n",
      "[epoch=  4, batch_cnt=  750] loss: 1.44147\n",
      "Train Acc: 48 %\n",
      "Accuracy: 48 %\n",
      "[epoch=  4, batch_cnt= 1000] loss: 1.39218\n",
      "Train Acc: 49 %\n",
      "Accuracy: 49 %\n",
      "[epoch=  4, batch_cnt= 1250] loss: 1.31075\n",
      "Train Acc: 51 %\n",
      "Accuracy: 51 %\n",
      "[epoch=  5, batch_cnt=  250] loss: 1.28494\n",
      "Train Acc: 54 %\n",
      "Accuracy: 53 %\n",
      "[epoch=  5, batch_cnt=  500] loss: 1.25614\n",
      "Train Acc: 56 %\n",
      "Accuracy: 55 %\n",
      "[epoch=  5, batch_cnt=  750] loss: 1.19363\n",
      "Train Acc: 55 %\n",
      "Accuracy: 54 %\n",
      "[epoch=  5, batch_cnt= 1000] loss: 1.18578\n",
      "Train Acc: 58 %\n",
      "Accuracy: 56 %\n",
      "[epoch=  5, batch_cnt= 1250] loss: 1.16280\n",
      "Train Acc: 60 %\n",
      "Accuracy: 58 %\n",
      "[epoch=  6, batch_cnt=  250] loss: 1.07317\n",
      "Train Acc: 63 %\n",
      "Accuracy: 62 %\n",
      "[epoch=  6, batch_cnt=  500] loss: 1.05769\n",
      "Train Acc: 63 %\n",
      "Accuracy: 61 %\n",
      "[epoch=  6, batch_cnt=  750] loss: 1.05111\n",
      "Train Acc: 64 %\n",
      "Accuracy: 62 %\n",
      "[epoch=  6, batch_cnt= 1000] loss: 1.03319\n",
      "Train Acc: 65 %\n",
      "Accuracy: 63 %\n",
      "[epoch=  6, batch_cnt= 1250] loss: 1.00203\n",
      "Train Acc: 67 %\n",
      "Accuracy: 65 %\n",
      "[epoch=  7, batch_cnt=  250] loss: 0.93939\n",
      "Train Acc: 68 %\n",
      "Accuracy: 65 %\n",
      "[epoch=  7, batch_cnt=  500] loss: 0.95236\n",
      "Train Acc: 68 %\n",
      "Accuracy: 65 %\n",
      "[epoch=  7, batch_cnt=  750] loss: 0.93161\n",
      "Train Acc: 70 %\n",
      "Accuracy: 68 %\n",
      "[epoch=  7, batch_cnt= 1000] loss: 0.90548\n",
      "Train Acc: 70 %\n",
      "Accuracy: 67 %\n",
      "[epoch=  7, batch_cnt= 1250] loss: 0.88050\n",
      "Train Acc: 71 %\n",
      "Accuracy: 68 %\n",
      "[epoch=  8, batch_cnt=  250] loss: 0.85406\n",
      "Train Acc: 71 %\n",
      "Accuracy: 68 %\n",
      "[epoch=  8, batch_cnt=  500] loss: 0.82951\n",
      "Train Acc: 74 %\n",
      "Accuracy: 71 %\n",
      "[epoch=  8, batch_cnt=  750] loss: 0.79835\n",
      "Train Acc: 75 %\n",
      "Accuracy: 71 %\n",
      "[epoch=  8, batch_cnt= 1000] loss: 0.79244\n",
      "Train Acc: 75 %\n",
      "Accuracy: 71 %\n",
      "[epoch=  8, batch_cnt= 1250] loss: 0.76636\n",
      "Train Acc: 76 %\n",
      "Accuracy: 72 %\n",
      "[epoch=  9, batch_cnt=  250] loss: 0.73303\n",
      "Train Acc: 75 %\n",
      "Accuracy: 71 %\n",
      "[epoch=  9, batch_cnt=  500] loss: 0.70226\n",
      "Train Acc: 77 %\n",
      "Accuracy: 73 %\n",
      "[epoch=  9, batch_cnt=  750] loss: 0.71257\n",
      "Train Acc: 77 %\n",
      "Accuracy: 73 %\n",
      "[epoch=  9, batch_cnt= 1000] loss: 0.71125\n",
      "Train Acc: 78 %\n",
      "Accuracy: 73 %\n",
      "[epoch=  9, batch_cnt= 1250] loss: 0.70984\n",
      "Train Acc: 79 %\n",
      "Accuracy: 74 %\n",
      "[epoch= 10, batch_cnt=  250] loss: 0.63909\n",
      "Train Acc: 79 %\n",
      "Accuracy: 74 %\n",
      "[epoch= 10, batch_cnt=  500] loss: 0.62514\n",
      "Train Acc: 80 %\n",
      "Accuracy: 75 %\n",
      "[epoch= 10, batch_cnt=  750] loss: 0.62205\n",
      "Train Acc: 80 %\n",
      "Accuracy: 75 %\n",
      "[epoch= 10, batch_cnt= 1000] loss: 0.64258\n",
      "Train Acc: 81 %\n",
      "Accuracy: 76 %\n",
      "[epoch= 10, batch_cnt= 1250] loss: 0.62675\n",
      "Train Acc: 81 %\n",
      "Accuracy: 75 %\n",
      "[epoch= 11, batch_cnt=  250] loss: 0.54708\n",
      "Train Acc: 82 %\n",
      "Accuracy: 76 %\n",
      "[epoch= 11, batch_cnt=  500] loss: 0.55001\n",
      "Train Acc: 83 %\n",
      "Accuracy: 77 %\n",
      "[epoch= 11, batch_cnt=  750] loss: 0.59218\n",
      "Train Acc: 79 %\n",
      "Accuracy: 73 %\n",
      "[epoch= 11, batch_cnt= 1000] loss: 0.57176\n",
      "Train Acc: 84 %\n",
      "Accuracy: 77 %\n",
      "[epoch= 11, batch_cnt= 1250] loss: 0.58274\n",
      "Train Acc: 82 %\n",
      "Accuracy: 76 %\n",
      "[epoch= 12, batch_cnt=  250] loss: 0.51481\n",
      "Train Acc: 82 %\n",
      "Accuracy: 76 %\n",
      "[epoch= 12, batch_cnt=  500] loss: 0.52268\n",
      "Train Acc: 83 %\n",
      "Accuracy: 77 %\n",
      "[epoch= 12, batch_cnt=  750] loss: 0.50555\n",
      "Train Acc: 84 %\n",
      "Accuracy: 77 %\n",
      "[epoch= 12, batch_cnt= 1000] loss: 0.50756\n",
      "Train Acc: 86 %\n",
      "Accuracy: 79 %\n",
      "[epoch= 12, batch_cnt= 1250] loss: 0.51528\n",
      "Train Acc: 86 %\n",
      "Accuracy: 78 %\n",
      "[epoch= 13, batch_cnt=  250] loss: 0.45365\n",
      "Train Acc: 84 %\n",
      "Accuracy: 77 %\n",
      "[epoch= 13, batch_cnt=  500] loss: 0.46682\n",
      "Train Acc: 86 %\n",
      "Accuracy: 78 %\n",
      "[epoch= 13, batch_cnt=  750] loss: 0.49092\n",
      "Train Acc: 86 %\n",
      "Accuracy: 78 %\n",
      "[epoch= 13, batch_cnt= 1000] loss: 0.47082\n",
      "Train Acc: 86 %\n",
      "Accuracy: 78 %\n",
      "[epoch= 13, batch_cnt= 1250] loss: 0.46092\n",
      "Train Acc: 87 %\n",
      "Accuracy: 79 %\n",
      "[epoch= 14, batch_cnt=  250] loss: 0.39527\n",
      "Train Acc: 87 %\n",
      "Accuracy: 79 %\n",
      "[epoch= 14, batch_cnt=  500] loss: 0.43641\n",
      "Train Acc: 87 %\n",
      "Accuracy: 78 %\n",
      "[epoch= 14, batch_cnt=  750] loss: 0.43015\n",
      "Train Acc: 87 %\n",
      "Accuracy: 78 %\n",
      "[epoch= 14, batch_cnt= 1000] loss: 0.39562\n",
      "Train Acc: 88 %\n",
      "Accuracy: 79 %\n",
      "[epoch= 14, batch_cnt= 1250] loss: 0.40847\n",
      "Train Acc: 89 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 15, batch_cnt=  250] loss: 0.35248\n",
      "Train Acc: 89 %\n",
      "Accuracy: 79 %\n",
      "[epoch= 15, batch_cnt=  500] loss: 0.35493\n",
      "Train Acc: 90 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 15, batch_cnt=  750] loss: 0.35662\n",
      "Train Acc: 90 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 15, batch_cnt= 1000] loss: 0.37284\n",
      "Train Acc: 89 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 15, batch_cnt= 1250] loss: 0.37358\n",
      "Train Acc: 88 %\n",
      "Accuracy: 79 %\n",
      "[epoch= 16, batch_cnt=  250] loss: 0.32093\n",
      "Train Acc: 91 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 16, batch_cnt=  500] loss: 0.33093\n",
      "Train Acc: 90 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 16, batch_cnt=  750] loss: 0.33888\n",
      "Train Acc: 90 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 16, batch_cnt= 1000] loss: 0.32609\n",
      "Train Acc: 91 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 16, batch_cnt= 1250] loss: 0.33704\n",
      "Train Acc: 91 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 17, batch_cnt=  250] loss: 0.26143\n",
      "Train Acc: 92 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 17, batch_cnt=  500] loss: 0.28212\n",
      "Train Acc: 92 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 17, batch_cnt=  750] loss: 0.29833\n",
      "Train Acc: 90 %\n",
      "Accuracy: 79 %\n",
      "[epoch= 17, batch_cnt= 1000] loss: 0.29157\n",
      "Train Acc: 92 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 17, batch_cnt= 1250] loss: 0.29538\n",
      "Train Acc: 91 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 18, batch_cnt=  250] loss: 0.24521\n",
      "Train Acc: 92 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 18, batch_cnt=  500] loss: 0.25279\n",
      "Train Acc: 93 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 18, batch_cnt=  750] loss: 0.26517\n",
      "Train Acc: 92 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 18, batch_cnt= 1000] loss: 0.27944\n",
      "Train Acc: 93 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 18, batch_cnt= 1250] loss: 0.26222\n",
      "Train Acc: 93 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 19, batch_cnt=  250] loss: 0.22126\n",
      "Train Acc: 93 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 19, batch_cnt=  500] loss: 0.23013\n",
      "Train Acc: 93 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 19, batch_cnt=  750] loss: 0.25289\n",
      "Train Acc: 93 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 19, batch_cnt= 1000] loss: 0.24211\n",
      "Train Acc: 93 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 19, batch_cnt= 1250] loss: 0.25319\n",
      "Train Acc: 92 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 20, batch_cnt=  250] loss: 0.20228\n",
      "Train Acc: 94 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 20, batch_cnt=  500] loss: 0.19289\n",
      "Train Acc: 94 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 20, batch_cnt=  750] loss: 0.21173\n",
      "Train Acc: 93 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 20, batch_cnt= 1000] loss: 0.23025\n",
      "Train Acc: 93 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 20, batch_cnt= 1250] loss: 0.21409\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 21, batch_cnt=  250] loss: 0.18542\n",
      "Train Acc: 94 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 21, batch_cnt=  500] loss: 0.16105\n",
      "Train Acc: 95 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 21, batch_cnt=  750] loss: 0.18667\n",
      "Train Acc: 95 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 21, batch_cnt= 1000] loss: 0.19758\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 21, batch_cnt= 1250] loss: 0.19611\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 22, batch_cnt=  250] loss: 0.16639\n",
      "Train Acc: 92 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 22, batch_cnt=  500] loss: 0.18195\n",
      "Train Acc: 94 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 22, batch_cnt=  750] loss: 0.19758\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 22, batch_cnt= 1000] loss: 0.17282\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 22, batch_cnt= 1250] loss: 0.19927\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 23, batch_cnt=  250] loss: 0.15831\n",
      "Train Acc: 96 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82 %\n",
      "[epoch= 23, batch_cnt=  500] loss: 0.15351\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 23, batch_cnt=  750] loss: 0.15040\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 23, batch_cnt= 1000] loss: 0.15406\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 23, batch_cnt= 1250] loss: 0.16066\n",
      "Train Acc: 95 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 24, batch_cnt=  250] loss: 0.12961\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 24, batch_cnt=  500] loss: 0.12954\n",
      "Train Acc: 94 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 24, batch_cnt=  750] loss: 0.16138\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 24, batch_cnt= 1000] loss: 0.15317\n",
      "Train Acc: 95 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 24, batch_cnt= 1250] loss: 0.14858\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 25, batch_cnt=  250] loss: 0.12500\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 25, batch_cnt=  500] loss: 0.11013\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 25, batch_cnt=  750] loss: 0.13729\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 25, batch_cnt= 1000] loss: 0.14577\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 25, batch_cnt= 1250] loss: 0.15016\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 26, batch_cnt=  250] loss: 0.12279\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 26, batch_cnt=  500] loss: 0.11484\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 26, batch_cnt=  750] loss: 0.12762\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 26, batch_cnt= 1000] loss: 0.12481\n",
      "Train Acc: 96 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 26, batch_cnt= 1250] loss: 0.13279\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 27, batch_cnt=  250] loss: 0.12128\n",
      "Train Acc: 95 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 27, batch_cnt=  500] loss: 0.13169\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 27, batch_cnt=  750] loss: 0.11828\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 27, batch_cnt= 1000] loss: 0.12076\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 27, batch_cnt= 1250] loss: 0.13191\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 28, batch_cnt=  250] loss: 0.09540\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 28, batch_cnt=  500] loss: 0.14544\n",
      "Train Acc: 93 %\n",
      "Accuracy: 79 %\n",
      "[epoch= 28, batch_cnt=  750] loss: 0.15417\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 28, batch_cnt= 1000] loss: 0.11942\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 28, batch_cnt= 1250] loss: 0.11489\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 29, batch_cnt=  250] loss: 0.09356\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 29, batch_cnt=  500] loss: 0.09886\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 29, batch_cnt=  750] loss: 0.10641\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 29, batch_cnt= 1000] loss: 0.10047\n",
      "Train Acc: 96 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 29, batch_cnt= 1250] loss: 0.10873\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 30, batch_cnt=  250] loss: 0.08135\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 30, batch_cnt=  500] loss: 0.09532\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 30, batch_cnt=  750] loss: 0.10103\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 30, batch_cnt= 1000] loss: 0.09368\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 30, batch_cnt= 1250] loss: 0.12272\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 31, batch_cnt=  250] loss: 0.10718\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 31, batch_cnt=  500] loss: 0.10088\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 31, batch_cnt=  750] loss: 0.08133\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 31, batch_cnt= 1000] loss: 0.09109\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 31, batch_cnt= 1250] loss: 0.08702\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 32, batch_cnt=  250] loss: 0.08841\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 32, batch_cnt=  500] loss: 0.07777\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 32, batch_cnt=  750] loss: 0.09076\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 32, batch_cnt= 1000] loss: 0.08377\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 32, batch_cnt= 1250] loss: 0.10614\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 33, batch_cnt=  250] loss: 0.08718\n",
      "Train Acc: 96 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 33, batch_cnt=  500] loss: 0.09503\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 33, batch_cnt=  750] loss: 0.10196\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 33, batch_cnt= 1000] loss: 0.08653\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 33, batch_cnt= 1250] loss: 0.08520\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 34, batch_cnt=  250] loss: 0.07198\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 34, batch_cnt=  500] loss: 0.07167\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 34, batch_cnt=  750] loss: 0.08416\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 34, batch_cnt= 1000] loss: 0.07311\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 34, batch_cnt= 1250] loss: 0.07518\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 35, batch_cnt=  250] loss: 0.06263\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 35, batch_cnt=  500] loss: 0.07661\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 35, batch_cnt=  750] loss: 0.06819\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 35, batch_cnt= 1000] loss: 0.08157\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 35, batch_cnt= 1250] loss: 0.08321\n",
      "Train Acc: 97 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 36, batch_cnt=  250] loss: 0.06789\n",
      "Train Acc: 96 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 36, batch_cnt=  500] loss: 0.08360\n",
      "Train Acc: 97 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 36, batch_cnt=  750] loss: 0.08630\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 36, batch_cnt= 1000] loss: 0.06290\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 36, batch_cnt= 1250] loss: 0.08228\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 37, batch_cnt=  250] loss: 0.06558\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 37, batch_cnt=  500] loss: 0.07843\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 37, batch_cnt=  750] loss: 0.07826\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 37, batch_cnt= 1000] loss: 0.07998\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 37, batch_cnt= 1250] loss: 0.07271\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 38, batch_cnt=  250] loss: 0.06563\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 38, batch_cnt=  500] loss: 0.09580\n",
      "Train Acc: 97 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 38, batch_cnt=  750] loss: 0.08518\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 38, batch_cnt= 1000] loss: 0.06433\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 38, batch_cnt= 1250] loss: 0.07142\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 39, batch_cnt=  250] loss: 0.05658\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 39, batch_cnt=  500] loss: 0.08288\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 39, batch_cnt=  750] loss: 0.05987\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 39, batch_cnt= 1000] loss: 0.06923\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 39, batch_cnt= 1250] loss: 0.05830\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 40, batch_cnt=  250] loss: 0.05731\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 40, batch_cnt=  500] loss: 0.06446\n",
      "Train Acc: 98 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 40, batch_cnt=  750] loss: 0.05186\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 40, batch_cnt= 1000] loss: 0.07277\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 40, batch_cnt= 1250] loss: 0.06808\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 41, batch_cnt=  250] loss: 0.05193\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 41, batch_cnt=  500] loss: 0.08639\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 41, batch_cnt=  750] loss: 0.08215\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 41, batch_cnt= 1000] loss: 0.08488\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 41, batch_cnt= 1250] loss: 0.07168\n",
      "Train Acc: 99 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 42, batch_cnt=  250] loss: 0.06495\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 42, batch_cnt=  500] loss: 0.06227\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 42, batch_cnt=  750] loss: 0.07844\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 42, batch_cnt= 1000] loss: 0.05500\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 42, batch_cnt= 1250] loss: 0.06695\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 43, batch_cnt=  250] loss: 0.07685\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 43, batch_cnt=  500] loss: 0.06987\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 43, batch_cnt=  750] loss: 0.05480\n",
      "Train Acc: 99 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 43, batch_cnt= 1000] loss: 0.04301\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 43, batch_cnt= 1250] loss: 0.04851\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 44, batch_cnt=  250] loss: 0.04507\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 44, batch_cnt=  500] loss: 0.05418\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 44, batch_cnt=  750] loss: 0.06390\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 44, batch_cnt= 1000] loss: 0.06943\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 44, batch_cnt= 1250] loss: 0.05634\n",
      "Train Acc: 99 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 45, batch_cnt=  250] loss: 0.04263\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 45, batch_cnt=  500] loss: 0.06513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 45, batch_cnt=  750] loss: 0.08093\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 45, batch_cnt= 1000] loss: 0.05200\n",
      "Train Acc: 99 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 45, batch_cnt= 1250] loss: 0.08727\n",
      "Train Acc: 96 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 46, batch_cnt=  250] loss: 0.08162\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 46, batch_cnt=  500] loss: 0.06489\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 46, batch_cnt=  750] loss: 0.04338\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 46, batch_cnt= 1000] loss: 0.05381\n",
      "Train Acc: 99 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 46, batch_cnt= 1250] loss: 0.03878\n",
      "Train Acc: 99 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 47, batch_cnt=  250] loss: 0.03104\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 47, batch_cnt=  500] loss: 0.05693\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 47, batch_cnt=  750] loss: 0.05324\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 47, batch_cnt= 1000] loss: 0.05056\n",
      "Train Acc: 99 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 47, batch_cnt= 1250] loss: 0.06641\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 48, batch_cnt=  250] loss: 0.05053\n",
      "Train Acc: 99 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 48, batch_cnt=  500] loss: 0.06282\n",
      "Train Acc: 99 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 48, batch_cnt=  750] loss: 0.11109\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 48, batch_cnt= 1000] loss: 0.09692\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 48, batch_cnt= 1250] loss: 0.04632\n",
      "Train Acc: 99 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 49, batch_cnt=  250] loss: 0.04827\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 49, batch_cnt=  500] loss: 0.04016\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 49, batch_cnt=  750] loss: 0.04226\n",
      "Train Acc: 99 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 49, batch_cnt= 1000] loss: 0.05258\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 49, batch_cnt= 1250] loss: 0.06831\n",
      "Train Acc: 99 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 50, batch_cnt=  250] loss: 0.03581\n",
      "Train Acc: 99 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 50, batch_cnt=  500] loss: 0.03868\n",
      "Train Acc: 99 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 50, batch_cnt=  750] loss: 0.04607\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 50, batch_cnt= 1000] loss: 0.05386\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 50, batch_cnt= 1250] loss: 0.05676\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type 'ndarray' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ed2f3031354b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\June\\Q56094077\\cvdl2020\\hw1\\models\\trainer\\trainer_kfold.py\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(self, width)\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[1;34m'acc'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[1;34m'loss'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m                 \u001b[1;34m'tacc'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch_tacc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m             }\n\u001b[0;32m    112\u001b[0m             \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cvdl2020\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;31m# a debuggability cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cvdl2020\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    428\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cvdl2020\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cvdl2020\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    435\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Circular reference detected\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cvdl2020\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[1;32m--> 180\u001b[1;33m                         o.__class__.__name__)\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type 'ndarray' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "trainer.training(width=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "epoch_loss = np.array(trainer.epoch_loss).flatten()\n",
    "epoch_acc = np.array(trainer.epoch_acc).flatten()\n",
    "epoch_tacc = np.array(trainer.epoch_tacc).flatten()\n",
    "\n",
    "epoch_loss = list(epoch_loss)\n",
    "epoch_acc = list(epoch_acc)\n",
    "epoch_tacc = list(epoch_tacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('epoch.json', 'w') as fp:\n",
    "    epoch_info = {\n",
    "        'acc': epoch_acc,\n",
    "        'loss': epoch_loss,\n",
    "        'tacc': epoch_tacc\n",
    "    }\n",
    "    json.dump(epoch_info, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'model_stat': trainer.model.state_dict(),\n",
    "    'optimizer_stat': trainer.optimizer.state_dict(),\n",
    "    'loss': trainer.criterion.state_dict(),\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'vgg16_adma_batch32.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from vgg16 import _Vgg16, Block\n",
    "from trainer.trainer_kfold import TrainerWithKFoldValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_16_adam = _Vgg16(Block, [2, 2, 3, 3, 3])\n",
    "optimizer_adam = optim.Adam(vgg_16_adam.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 64, 32, 32]          --\n",
      "|    └─Block: 2-1                        [-1, 64, 64, 64]          --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 64, 64, 64]          1,792\n",
      "|    |    └─BatchNorm2d: 3-2             [-1, 64, 64, 64]          128\n",
      "|    |    └─ReLU: 3-3                    [-1, 64, 64, 64]          --\n",
      "|    └─Block: 2-2                        [-1, 64, 64, 64]          --\n",
      "|    |    └─Conv2d: 3-4                  [-1, 64, 64, 64]          36,928\n",
      "|    |    └─BatchNorm2d: 3-5             [-1, 64, 64, 64]          128\n",
      "|    |    └─ReLU: 3-6                    [-1, 64, 64, 64]          --\n",
      "|    └─MaxPool2d: 2-3                    [-1, 64, 32, 32]          --\n",
      "├─Sequential: 1-2                        [-1, 128, 16, 16]         --\n",
      "|    └─Block: 2-4                        [-1, 128, 32, 32]         --\n",
      "|    |    └─Conv2d: 3-7                  [-1, 128, 32, 32]         73,856\n",
      "|    |    └─BatchNorm2d: 3-8             [-1, 128, 32, 32]         256\n",
      "|    |    └─ReLU: 3-9                    [-1, 128, 32, 32]         --\n",
      "|    └─Block: 2-5                        [-1, 128, 32, 32]         --\n",
      "|    |    └─Conv2d: 3-10                 [-1, 128, 32, 32]         147,584\n",
      "|    |    └─BatchNorm2d: 3-11            [-1, 128, 32, 32]         256\n",
      "|    |    └─ReLU: 3-12                   [-1, 128, 32, 32]         --\n",
      "|    └─MaxPool2d: 2-6                    [-1, 128, 16, 16]         --\n",
      "├─Sequential: 1-3                        [-1, 256, 8, 8]           --\n",
      "|    └─Block: 2-7                        [-1, 256, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-13                 [-1, 256, 16, 16]         295,168\n",
      "|    |    └─BatchNorm2d: 3-14            [-1, 256, 16, 16]         512\n",
      "|    |    └─ReLU: 3-15                   [-1, 256, 16, 16]         --\n",
      "|    └─Block: 2-8                        [-1, 256, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-16                 [-1, 256, 16, 16]         590,080\n",
      "|    |    └─BatchNorm2d: 3-17            [-1, 256, 16, 16]         512\n",
      "|    |    └─ReLU: 3-18                   [-1, 256, 16, 16]         --\n",
      "|    └─Block: 2-9                        [-1, 256, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-19                 [-1, 256, 16, 16]         590,080\n",
      "|    |    └─BatchNorm2d: 3-20            [-1, 256, 16, 16]         512\n",
      "|    |    └─ReLU: 3-21                   [-1, 256, 16, 16]         --\n",
      "|    └─MaxPool2d: 2-10                   [-1, 256, 8, 8]           --\n",
      "├─Sequential: 1-4                        [-1, 512, 4, 4]           --\n",
      "|    └─Block: 2-11                       [-1, 512, 8, 8]           --\n",
      "|    |    └─Conv2d: 3-22                 [-1, 512, 8, 8]           1,180,160\n",
      "|    |    └─BatchNorm2d: 3-23            [-1, 512, 8, 8]           1,024\n",
      "|    |    └─ReLU: 3-24                   [-1, 512, 8, 8]           --\n",
      "|    └─Block: 2-12                       [-1, 512, 8, 8]           --\n",
      "|    |    └─Conv2d: 3-25                 [-1, 512, 8, 8]           2,359,808\n",
      "|    |    └─BatchNorm2d: 3-26            [-1, 512, 8, 8]           1,024\n",
      "|    |    └─ReLU: 3-27                   [-1, 512, 8, 8]           --\n",
      "|    └─Block: 2-13                       [-1, 512, 8, 8]           --\n",
      "|    |    └─Conv2d: 3-28                 [-1, 512, 8, 8]           2,359,808\n",
      "|    |    └─BatchNorm2d: 3-29            [-1, 512, 8, 8]           1,024\n",
      "|    |    └─ReLU: 3-30                   [-1, 512, 8, 8]           --\n",
      "|    └─MaxPool2d: 2-14                   [-1, 512, 4, 4]           --\n",
      "├─Sequential: 1-5                        [-1, 512, 2, 2]           --\n",
      "|    └─Block: 2-15                       [-1, 512, 4, 4]           --\n",
      "|    |    └─Conv2d: 3-31                 [-1, 512, 4, 4]           2,359,808\n",
      "|    |    └─BatchNorm2d: 3-32            [-1, 512, 4, 4]           1,024\n",
      "|    |    └─ReLU: 3-33                   [-1, 512, 4, 4]           --\n",
      "|    └─Block: 2-16                       [-1, 512, 4, 4]           --\n",
      "|    |    └─Conv2d: 3-34                 [-1, 512, 4, 4]           2,359,808\n",
      "|    |    └─BatchNorm2d: 3-35            [-1, 512, 4, 4]           1,024\n",
      "|    |    └─ReLU: 3-36                   [-1, 512, 4, 4]           --\n",
      "|    └─Block: 2-17                       [-1, 512, 4, 4]           --\n",
      "|    |    └─Conv2d: 3-37                 [-1, 512, 4, 4]           2,359,808\n",
      "|    |    └─BatchNorm2d: 3-38            [-1, 512, 4, 4]           1,024\n",
      "|    |    └─ReLU: 3-39                   [-1, 512, 4, 4]           --\n",
      "|    └─MaxPool2d: 2-18                   [-1, 512, 2, 2]           --\n",
      "├─AdaptiveAvgPool2d: 1-6                 [-1, 512, 1, 1]           --\n",
      "├─Flatten: 1-7                           [-1, 512]                 --\n",
      "├─Sequential: 1-8                        [-1, 4096]                --\n",
      "|    └─Linear: 2-19                      [-1, 4096]                2,101,248\n",
      "|    └─ReLU: 2-20                        [-1, 4096]                --\n",
      "|    └─Dropout: 2-21                     [-1, 4096]                --\n",
      "├─Sequential: 1-9                        [-1, 4096]                --\n",
      "|    └─Linear: 2-22                      [-1, 4096]                16,781,312\n",
      "|    └─ReLU: 2-23                        [-1, 4096]                --\n",
      "|    └─Dropout: 2-24                     [-1, 4096]                --\n",
      "├─Linear: 1-10                           [-1, 10]                  40,970\n",
      "==========================================================================================\n",
      "Total params: 33,646,666\n",
      "Trainable params: 33,646,666\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 1.32\n",
      "==========================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 16.94\n",
      "Params size (MB): 128.35\n",
      "Estimated Total Size (MB): 145.34\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 64, 32, 32]          --\n",
       "|    └─Block: 2-1                        [-1, 64, 64, 64]          --\n",
       "|    |    └─Conv2d: 3-1                  [-1, 64, 64, 64]          1,792\n",
       "|    |    └─BatchNorm2d: 3-2             [-1, 64, 64, 64]          128\n",
       "|    |    └─ReLU: 3-3                    [-1, 64, 64, 64]          --\n",
       "|    └─Block: 2-2                        [-1, 64, 64, 64]          --\n",
       "|    |    └─Conv2d: 3-4                  [-1, 64, 64, 64]          36,928\n",
       "|    |    └─BatchNorm2d: 3-5             [-1, 64, 64, 64]          128\n",
       "|    |    └─ReLU: 3-6                    [-1, 64, 64, 64]          --\n",
       "|    └─MaxPool2d: 2-3                    [-1, 64, 32, 32]          --\n",
       "├─Sequential: 1-2                        [-1, 128, 16, 16]         --\n",
       "|    └─Block: 2-4                        [-1, 128, 32, 32]         --\n",
       "|    |    └─Conv2d: 3-7                  [-1, 128, 32, 32]         73,856\n",
       "|    |    └─BatchNorm2d: 3-8             [-1, 128, 32, 32]         256\n",
       "|    |    └─ReLU: 3-9                    [-1, 128, 32, 32]         --\n",
       "|    └─Block: 2-5                        [-1, 128, 32, 32]         --\n",
       "|    |    └─Conv2d: 3-10                 [-1, 128, 32, 32]         147,584\n",
       "|    |    └─BatchNorm2d: 3-11            [-1, 128, 32, 32]         256\n",
       "|    |    └─ReLU: 3-12                   [-1, 128, 32, 32]         --\n",
       "|    └─MaxPool2d: 2-6                    [-1, 128, 16, 16]         --\n",
       "├─Sequential: 1-3                        [-1, 256, 8, 8]           --\n",
       "|    └─Block: 2-7                        [-1, 256, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-13                 [-1, 256, 16, 16]         295,168\n",
       "|    |    └─BatchNorm2d: 3-14            [-1, 256, 16, 16]         512\n",
       "|    |    └─ReLU: 3-15                   [-1, 256, 16, 16]         --\n",
       "|    └─Block: 2-8                        [-1, 256, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-16                 [-1, 256, 16, 16]         590,080\n",
       "|    |    └─BatchNorm2d: 3-17            [-1, 256, 16, 16]         512\n",
       "|    |    └─ReLU: 3-18                   [-1, 256, 16, 16]         --\n",
       "|    └─Block: 2-9                        [-1, 256, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-19                 [-1, 256, 16, 16]         590,080\n",
       "|    |    └─BatchNorm2d: 3-20            [-1, 256, 16, 16]         512\n",
       "|    |    └─ReLU: 3-21                   [-1, 256, 16, 16]         --\n",
       "|    └─MaxPool2d: 2-10                   [-1, 256, 8, 8]           --\n",
       "├─Sequential: 1-4                        [-1, 512, 4, 4]           --\n",
       "|    └─Block: 2-11                       [-1, 512, 8, 8]           --\n",
       "|    |    └─Conv2d: 3-22                 [-1, 512, 8, 8]           1,180,160\n",
       "|    |    └─BatchNorm2d: 3-23            [-1, 512, 8, 8]           1,024\n",
       "|    |    └─ReLU: 3-24                   [-1, 512, 8, 8]           --\n",
       "|    └─Block: 2-12                       [-1, 512, 8, 8]           --\n",
       "|    |    └─Conv2d: 3-25                 [-1, 512, 8, 8]           2,359,808\n",
       "|    |    └─BatchNorm2d: 3-26            [-1, 512, 8, 8]           1,024\n",
       "|    |    └─ReLU: 3-27                   [-1, 512, 8, 8]           --\n",
       "|    └─Block: 2-13                       [-1, 512, 8, 8]           --\n",
       "|    |    └─Conv2d: 3-28                 [-1, 512, 8, 8]           2,359,808\n",
       "|    |    └─BatchNorm2d: 3-29            [-1, 512, 8, 8]           1,024\n",
       "|    |    └─ReLU: 3-30                   [-1, 512, 8, 8]           --\n",
       "|    └─MaxPool2d: 2-14                   [-1, 512, 4, 4]           --\n",
       "├─Sequential: 1-5                        [-1, 512, 2, 2]           --\n",
       "|    └─Block: 2-15                       [-1, 512, 4, 4]           --\n",
       "|    |    └─Conv2d: 3-31                 [-1, 512, 4, 4]           2,359,808\n",
       "|    |    └─BatchNorm2d: 3-32            [-1, 512, 4, 4]           1,024\n",
       "|    |    └─ReLU: 3-33                   [-1, 512, 4, 4]           --\n",
       "|    └─Block: 2-16                       [-1, 512, 4, 4]           --\n",
       "|    |    └─Conv2d: 3-34                 [-1, 512, 4, 4]           2,359,808\n",
       "|    |    └─BatchNorm2d: 3-35            [-1, 512, 4, 4]           1,024\n",
       "|    |    └─ReLU: 3-36                   [-1, 512, 4, 4]           --\n",
       "|    └─Block: 2-17                       [-1, 512, 4, 4]           --\n",
       "|    |    └─Conv2d: 3-37                 [-1, 512, 4, 4]           2,359,808\n",
       "|    |    └─BatchNorm2d: 3-38            [-1, 512, 4, 4]           1,024\n",
       "|    |    └─ReLU: 3-39                   [-1, 512, 4, 4]           --\n",
       "|    └─MaxPool2d: 2-18                   [-1, 512, 2, 2]           --\n",
       "├─AdaptiveAvgPool2d: 1-6                 [-1, 512, 1, 1]           --\n",
       "├─Flatten: 1-7                           [-1, 512]                 --\n",
       "├─Sequential: 1-8                        [-1, 4096]                --\n",
       "|    └─Linear: 2-19                      [-1, 4096]                2,101,248\n",
       "|    └─ReLU: 2-20                        [-1, 4096]                --\n",
       "|    └─Dropout: 2-21                     [-1, 4096]                --\n",
       "├─Sequential: 1-9                        [-1, 4096]                --\n",
       "|    └─Linear: 2-22                      [-1, 4096]                16,781,312\n",
       "|    └─ReLU: 2-23                        [-1, 4096]                --\n",
       "|    └─Dropout: 2-24                     [-1, 4096]                --\n",
       "├─Linear: 1-10                           [-1, 10]                  40,970\n",
       "==========================================================================================\n",
       "Total params: 33,646,666\n",
       "Trainable params: 33,646,666\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.32\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 16.94\n",
       "Params size (MB): 128.35\n",
       "Estimated Total Size (MB): 145.34\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(vgg_16_adam, (3, 64, 64), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TrainerWithKFoldValidation(vgg_16_adam, optimizer_adam, trainset, testset, save_name=\"vgg16_adam_batch32_fold5\", path=None, epoch=EPOCH, batch=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch=  1, batch_cnt=  250] loss: 2.27972\n",
      "Train Acc: 18 %\n",
      "Accuracy: 19 %\n",
      "[epoch=  1, batch_cnt=  500] loss: 2.03966\n",
      "Train Acc: 21 %\n",
      "Accuracy: 21 %\n",
      "[epoch=  1, batch_cnt=  750] loss: 1.95427\n",
      "Train Acc: 22 %\n",
      "Accuracy: 22 %\n",
      "[epoch=  1, batch_cnt= 1000] loss: 1.86722\n",
      "Train Acc: 25 %\n",
      "Accuracy: 25 %\n",
      "[epoch=  1, batch_cnt= 1250] loss: 1.82204\n",
      "Train Acc: 27 %\n",
      "Accuracy: 27 %\n",
      "[epoch=  2, batch_cnt=  250] loss: 1.79648\n",
      "Train Acc: 27 %\n",
      "Accuracy: 27 %\n",
      "[epoch=  2, batch_cnt=  500] loss: 1.74341\n",
      "Train Acc: 30 %\n",
      "Accuracy: 29 %\n",
      "[epoch=  2, batch_cnt=  750] loss: 1.73984\n",
      "Train Acc: 30 %\n",
      "Accuracy: 29 %\n",
      "[epoch=  2, batch_cnt= 1000] loss: 1.71296\n",
      "Train Acc: 32 %\n",
      "Accuracy: 32 %\n",
      "[epoch=  2, batch_cnt= 1250] loss: 1.69031\n",
      "Train Acc: 34 %\n",
      "Accuracy: 33 %\n",
      "[epoch=  3, batch_cnt=  250] loss: 1.64582\n",
      "Train Acc: 37 %\n",
      "Accuracy: 37 %\n",
      "[epoch=  3, batch_cnt=  500] loss: 1.60390\n",
      "Train Acc: 38 %\n",
      "Accuracy: 38 %\n",
      "[epoch=  3, batch_cnt=  750] loss: 1.55696\n",
      "Train Acc: 39 %\n",
      "Accuracy: 40 %\n",
      "[epoch=  3, batch_cnt= 1000] loss: 1.53831\n",
      "Train Acc: 40 %\n",
      "Accuracy: 40 %\n",
      "[epoch=  3, batch_cnt= 1250] loss: 1.51789\n",
      "Train Acc: 42 %\n",
      "Accuracy: 42 %\n",
      "[epoch=  4, batch_cnt=  250] loss: 1.46220\n",
      "Train Acc: 44 %\n",
      "Accuracy: 44 %\n",
      "[epoch=  4, batch_cnt=  500] loss: 1.42612\n",
      "Train Acc: 49 %\n",
      "Accuracy: 49 %\n",
      "[epoch=  4, batch_cnt=  750] loss: 1.38285\n",
      "Train Acc: 50 %\n",
      "Accuracy: 50 %\n",
      "[epoch=  4, batch_cnt= 1000] loss: 1.37487\n",
      "Train Acc: 52 %\n",
      "Accuracy: 51 %\n",
      "[epoch=  4, batch_cnt= 1250] loss: 1.27197\n",
      "Train Acc: 56 %\n",
      "Accuracy: 55 %\n",
      "[epoch=  5, batch_cnt=  250] loss: 1.23683\n",
      "Train Acc: 57 %\n",
      "Accuracy: 56 %\n",
      "[epoch=  5, batch_cnt=  500] loss: 1.22444\n",
      "Train Acc: 55 %\n",
      "Accuracy: 55 %\n",
      "[epoch=  5, batch_cnt=  750] loss: 1.19566\n",
      "Train Acc: 60 %\n",
      "Accuracy: 59 %\n",
      "[epoch=  5, batch_cnt= 1000] loss: 1.12825\n",
      "Train Acc: 61 %\n",
      "Accuracy: 61 %\n",
      "[epoch=  5, batch_cnt= 1250] loss: 1.08836\n",
      "Train Acc: 64 %\n",
      "Accuracy: 63 %\n",
      "[epoch=  6, batch_cnt=  250] loss: 1.04947\n",
      "Train Acc: 65 %\n",
      "Accuracy: 63 %\n",
      "[epoch=  6, batch_cnt=  500] loss: 1.01267\n",
      "Train Acc: 67 %\n",
      "Accuracy: 66 %\n",
      "[epoch=  6, batch_cnt=  750] loss: 0.98336\n",
      "Train Acc: 67 %\n",
      "Accuracy: 64 %\n",
      "[epoch=  6, batch_cnt= 1000] loss: 0.97302\n",
      "Train Acc: 69 %\n",
      "Accuracy: 67 %\n",
      "[epoch=  6, batch_cnt= 1250] loss: 0.94718\n",
      "Train Acc: 69 %\n",
      "Accuracy: 68 %\n",
      "[epoch=  7, batch_cnt=  250] loss: 0.88023\n",
      "Train Acc: 70 %\n",
      "Accuracy: 68 %\n",
      "[epoch=  7, batch_cnt=  500] loss: 0.88026\n",
      "Train Acc: 70 %\n",
      "Accuracy: 68 %\n",
      "[epoch=  7, batch_cnt=  750] loss: 0.86088\n",
      "Train Acc: 73 %\n",
      "Accuracy: 70 %\n",
      "[epoch=  7, batch_cnt= 1000] loss: 0.85555\n",
      "Train Acc: 73 %\n",
      "Accuracy: 70 %\n",
      "[epoch=  7, batch_cnt= 1250] loss: 0.82204\n",
      "Train Acc: 73 %\n",
      "Accuracy: 71 %\n",
      "[epoch=  8, batch_cnt=  250] loss: 0.74873\n",
      "Train Acc: 73 %\n",
      "Accuracy: 71 %\n",
      "[epoch=  8, batch_cnt=  500] loss: 0.76233\n",
      "Train Acc: 75 %\n",
      "Accuracy: 72 %\n",
      "[epoch=  8, batch_cnt=  750] loss: 0.76809\n",
      "Train Acc: 76 %\n",
      "Accuracy: 73 %\n",
      "[epoch=  8, batch_cnt= 1000] loss: 0.75696\n",
      "Train Acc: 77 %\n",
      "Accuracy: 73 %\n",
      "[epoch=  8, batch_cnt= 1250] loss: 0.73957\n",
      "Train Acc: 78 %\n",
      "Accuracy: 75 %\n",
      "[epoch=  9, batch_cnt=  250] loss: 0.70820\n",
      "Train Acc: 79 %\n",
      "Accuracy: 75 %\n",
      "[epoch=  9, batch_cnt=  500] loss: 0.67648\n",
      "Train Acc: 79 %\n",
      "Accuracy: 75 %\n",
      "[epoch=  9, batch_cnt=  750] loss: 0.67655\n",
      "Train Acc: 79 %\n",
      "Accuracy: 74 %\n",
      "[epoch=  9, batch_cnt= 1000] loss: 0.66213\n",
      "Train Acc: 79 %\n",
      "Accuracy: 75 %\n",
      "[epoch=  9, batch_cnt= 1250] loss: 0.65099\n",
      "Train Acc: 80 %\n",
      "Accuracy: 76 %\n",
      "[epoch= 10, batch_cnt=  250] loss: 0.56869\n",
      "Train Acc: 80 %\n",
      "Accuracy: 76 %\n",
      "[epoch= 10, batch_cnt=  500] loss: 0.63801\n",
      "Train Acc: 80 %\n",
      "Accuracy: 75 %\n",
      "[epoch= 10, batch_cnt=  750] loss: 0.60209\n",
      "Train Acc: 80 %\n",
      "Accuracy: 75 %\n",
      "[epoch= 10, batch_cnt= 1000] loss: 0.61044\n",
      "Train Acc: 82 %\n",
      "Accuracy: 77 %\n",
      "[epoch= 10, batch_cnt= 1250] loss: 0.59568\n",
      "Train Acc: 82 %\n",
      "Accuracy: 77 %\n",
      "[epoch= 11, batch_cnt=  250] loss: 0.54712\n",
      "Train Acc: 83 %\n",
      "Accuracy: 77 %\n",
      "[epoch= 11, batch_cnt=  500] loss: 0.54295\n",
      "Train Acc: 83 %\n",
      "Accuracy: 78 %\n",
      "[epoch= 11, batch_cnt=  750] loss: 0.54078\n",
      "Train Acc: 84 %\n",
      "Accuracy: 78 %\n",
      "[epoch= 11, batch_cnt= 1000] loss: 0.52559\n",
      "Train Acc: 84 %\n",
      "Accuracy: 79 %\n",
      "[epoch= 11, batch_cnt= 1250] loss: 0.56097\n",
      "Train Acc: 85 %\n",
      "Accuracy: 79 %\n",
      "[epoch= 12, batch_cnt=  250] loss: 0.47709\n",
      "Train Acc: 84 %\n",
      "Accuracy: 78 %\n",
      "[epoch= 12, batch_cnt=  500] loss: 0.48395\n",
      "Train Acc: 85 %\n",
      "Accuracy: 79 %\n",
      "[epoch= 12, batch_cnt=  750] loss: 0.49029\n",
      "Train Acc: 85 %\n",
      "Accuracy: 78 %\n",
      "[epoch= 12, batch_cnt= 1000] loss: 0.49725\n",
      "Train Acc: 86 %\n",
      "Accuracy: 79 %\n",
      "[epoch= 12, batch_cnt= 1250] loss: 0.49418\n",
      "Train Acc: 87 %\n",
      "Accuracy: 79 %\n",
      "[epoch= 13, batch_cnt=  250] loss: 0.41027\n",
      "Train Acc: 87 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 13, batch_cnt=  500] loss: 0.42930\n",
      "Train Acc: 87 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 13, batch_cnt=  750] loss: 0.44754\n",
      "Train Acc: 85 %\n",
      "Accuracy: 78 %\n",
      "[epoch= 13, batch_cnt= 1000] loss: 0.48070\n",
      "Train Acc: 88 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 13, batch_cnt= 1250] loss: 0.44044\n",
      "Train Acc: 83 %\n",
      "Accuracy: 75 %\n",
      "[epoch= 14, batch_cnt=  250] loss: 0.39271\n",
      "Train Acc: 88 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 14, batch_cnt=  500] loss: 0.39112\n",
      "Train Acc: 89 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 14, batch_cnt=  750] loss: 0.39030\n",
      "Train Acc: 89 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 14, batch_cnt= 1000] loss: 0.39624\n",
      "Train Acc: 89 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 14, batch_cnt= 1250] loss: 0.38540\n",
      "Train Acc: 89 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 15, batch_cnt=  250] loss: 0.34305\n",
      "Train Acc: 89 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 15, batch_cnt=  500] loss: 0.33706\n",
      "Train Acc: 90 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 15, batch_cnt=  750] loss: 0.35578\n",
      "Train Acc: 90 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 15, batch_cnt= 1000] loss: 0.36336\n",
      "Train Acc: 90 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 15, batch_cnt= 1250] loss: 0.37157\n",
      "Train Acc: 91 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 16, batch_cnt=  250] loss: 0.29410\n",
      "Train Acc: 90 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 16, batch_cnt=  500] loss: 0.32543\n",
      "Train Acc: 91 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 16, batch_cnt=  750] loss: 0.30923\n",
      "Train Acc: 91 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 16, batch_cnt= 1000] loss: 0.32860\n",
      "Train Acc: 90 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 16, batch_cnt= 1250] loss: 0.32048\n",
      "Train Acc: 92 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 17, batch_cnt=  250] loss: 0.27504\n",
      "Train Acc: 92 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 17, batch_cnt=  500] loss: 0.25695\n",
      "Train Acc: 92 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 17, batch_cnt=  750] loss: 0.29842\n",
      "Train Acc: 92 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 17, batch_cnt= 1000] loss: 0.30845\n",
      "Train Acc: 92 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 17, batch_cnt= 1250] loss: 0.29029\n",
      "Train Acc: 92 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 18, batch_cnt=  250] loss: 0.28919\n",
      "Train Acc: 93 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 18, batch_cnt=  500] loss: 0.24325\n",
      "Train Acc: 93 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 18, batch_cnt=  750] loss: 0.26432\n",
      "Train Acc: 93 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 18, batch_cnt= 1000] loss: 0.24028\n",
      "Train Acc: 93 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 18, batch_cnt= 1250] loss: 0.27229\n",
      "Train Acc: 92 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 19, batch_cnt=  250] loss: 0.24509\n",
      "Train Acc: 92 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 19, batch_cnt=  500] loss: 0.26307\n",
      "Train Acc: 94 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 19, batch_cnt=  750] loss: 0.24518\n",
      "Train Acc: 94 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 19, batch_cnt= 1000] loss: 0.21985\n",
      "Train Acc: 93 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 19, batch_cnt= 1250] loss: 0.22134\n",
      "Train Acc: 95 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 20, batch_cnt=  250] loss: 0.18920\n",
      "Train Acc: 93 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 20, batch_cnt=  500] loss: 0.22066\n",
      "Train Acc: 94 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 20, batch_cnt=  750] loss: 0.21233\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 20, batch_cnt= 1000] loss: 0.20550\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 20, batch_cnt= 1250] loss: 0.21803\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 21, batch_cnt=  250] loss: 0.17627\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 21, batch_cnt=  500] loss: 0.17931\n",
      "Train Acc: 94 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 21, batch_cnt=  750] loss: 0.19233\n",
      "Train Acc: 93 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 21, batch_cnt= 1000] loss: 0.21327\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 21, batch_cnt= 1250] loss: 0.18905\n",
      "Train Acc: 94 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 22, batch_cnt=  250] loss: 0.15804\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 22, batch_cnt=  500] loss: 0.15604\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 22, batch_cnt=  750] loss: 0.17937\n",
      "Train Acc: 95 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 22, batch_cnt= 1000] loss: 0.19754\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 22, batch_cnt= 1250] loss: 0.18238\n",
      "Train Acc: 96 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 23, batch_cnt=  250] loss: 0.14850\n",
      "Train Acc: 95 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82 %\n",
      "[epoch= 23, batch_cnt=  500] loss: 0.17185\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 23, batch_cnt=  750] loss: 0.15952\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 23, batch_cnt= 1000] loss: 0.17538\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 23, batch_cnt= 1250] loss: 0.16415\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 24, batch_cnt=  250] loss: 0.13792\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 24, batch_cnt=  500] loss: 0.14935\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 24, batch_cnt=  750] loss: 0.14844\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 24, batch_cnt= 1000] loss: 0.19800\n",
      "Train Acc: 95 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 24, batch_cnt= 1250] loss: 0.15791\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 25, batch_cnt=  250] loss: 0.20438\n",
      "Train Acc: 93 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 25, batch_cnt=  500] loss: 0.16291\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 25, batch_cnt=  750] loss: 0.11948\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 25, batch_cnt= 1000] loss: 0.14316\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 25, batch_cnt= 1250] loss: 0.12748\n",
      "Train Acc: 96 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 26, batch_cnt=  250] loss: 0.10153\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 26, batch_cnt=  500] loss: 0.11532\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 26, batch_cnt=  750] loss: 0.11695\n",
      "Train Acc: 94 %\n",
      "Accuracy: 80 %\n",
      "[epoch= 26, batch_cnt= 1000] loss: 0.13617\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 26, batch_cnt= 1250] loss: 0.14219\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 27, batch_cnt=  250] loss: 0.08798\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 27, batch_cnt=  500] loss: 0.09343\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 27, batch_cnt=  750] loss: 0.12325\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 27, batch_cnt= 1000] loss: 0.12322\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 27, batch_cnt= 1250] loss: 0.13009\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 28, batch_cnt=  250] loss: 0.09548\n",
      "Train Acc: 96 %\n",
      "Accuracy: 81 %\n",
      "[epoch= 28, batch_cnt=  500] loss: 0.13709\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 28, batch_cnt=  750] loss: 0.12623\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 28, batch_cnt= 1000] loss: 0.11101\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 28, batch_cnt= 1250] loss: 0.13985\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 29, batch_cnt=  250] loss: 0.08391\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 29, batch_cnt=  500] loss: 0.12057\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 29, batch_cnt=  750] loss: 0.09188\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 29, batch_cnt= 1000] loss: 0.09614\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 29, batch_cnt= 1250] loss: 0.10451\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 30, batch_cnt=  250] loss: 0.09582\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 30, batch_cnt=  500] loss: 0.10199\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 30, batch_cnt=  750] loss: 0.11511\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 30, batch_cnt= 1000] loss: 0.10568\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 30, batch_cnt= 1250] loss: 0.10400\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 31, batch_cnt=  250] loss: 0.10018\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 31, batch_cnt=  500] loss: 0.09861\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 31, batch_cnt=  750] loss: 0.10586\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 31, batch_cnt= 1000] loss: 0.09079\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 31, batch_cnt= 1250] loss: 0.07618\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 32, batch_cnt=  250] loss: 0.08258\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 32, batch_cnt=  500] loss: 0.11832\n",
      "Train Acc: 96 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 32, batch_cnt=  750] loss: 0.09898\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 32, batch_cnt= 1000] loss: 0.09698\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 32, batch_cnt= 1250] loss: 0.09291\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 33, batch_cnt=  250] loss: 0.07055\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 33, batch_cnt=  500] loss: 0.07287\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 33, batch_cnt=  750] loss: 0.08898\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 33, batch_cnt= 1000] loss: 0.08033\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 33, batch_cnt= 1250] loss: 0.08820\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 34, batch_cnt=  250] loss: 0.06942\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 34, batch_cnt=  500] loss: 0.08314\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 34, batch_cnt=  750] loss: 0.07711\n",
      "Train Acc: 98 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 34, batch_cnt= 1000] loss: 0.09714\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 34, batch_cnt= 1250] loss: 0.08511\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 35, batch_cnt=  250] loss: 0.07677\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 35, batch_cnt=  500] loss: 0.06791\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 35, batch_cnt=  750] loss: 0.06787\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 35, batch_cnt= 1000] loss: 0.08834\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 35, batch_cnt= 1250] loss: 0.09206\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 36, batch_cnt=  250] loss: 0.06739\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 36, batch_cnt=  500] loss: 0.06636\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 36, batch_cnt=  750] loss: 0.06862\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 36, batch_cnt= 1000] loss: 0.10836\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 36, batch_cnt= 1250] loss: 0.08602\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 37, batch_cnt=  250] loss: 0.07045\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 37, batch_cnt=  500] loss: 0.06090\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 37, batch_cnt=  750] loss: 0.07670\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 37, batch_cnt= 1000] loss: 0.11224\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 37, batch_cnt= 1250] loss: 0.07591\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 38, batch_cnt=  250] loss: 0.07187\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 38, batch_cnt=  500] loss: 0.07475\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 38, batch_cnt=  750] loss: 0.07996\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 38, batch_cnt= 1000] loss: 0.06033\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 38, batch_cnt= 1250] loss: 0.05353\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 39, batch_cnt=  250] loss: 0.08891\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 39, batch_cnt=  500] loss: 0.08438\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 39, batch_cnt=  750] loss: 0.06938\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 39, batch_cnt= 1000] loss: 0.05533\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 39, batch_cnt= 1250] loss: 0.08149\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 40, batch_cnt=  250] loss: 0.05774\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 40, batch_cnt=  500] loss: 0.07560\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 40, batch_cnt=  750] loss: 0.07710\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 40, batch_cnt= 1000] loss: 0.05165\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 40, batch_cnt= 1250] loss: 0.06452\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 41, batch_cnt=  250] loss: 0.05712\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 41, batch_cnt=  500] loss: 0.05037\n",
      "Train Acc: 97 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 41, batch_cnt=  750] loss: 0.06370\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 41, batch_cnt= 1000] loss: 0.07370\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 41, batch_cnt= 1250] loss: 0.06648\n",
      "Train Acc: 99 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 42, batch_cnt=  250] loss: 0.07624\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 42, batch_cnt=  500] loss: 0.06542\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 42, batch_cnt=  750] loss: 0.09661\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 42, batch_cnt= 1000] loss: 0.08729\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 42, batch_cnt= 1250] loss: 0.05686\n",
      "Train Acc: 99 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 43, batch_cnt=  250] loss: 0.04735\n",
      "Train Acc: 99 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 43, batch_cnt=  500] loss: 0.04198\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 43, batch_cnt=  750] loss: 0.04283\n",
      "Train Acc: 98 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 43, batch_cnt= 1000] loss: 0.07258\n",
      "Train Acc: 98 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 43, batch_cnt= 1250] loss: 0.08419\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 44, batch_cnt=  250] loss: 0.06413\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 44, batch_cnt=  500] loss: 0.06318\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 44, batch_cnt=  750] loss: 0.07158\n",
      "Train Acc: 99 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 44, batch_cnt= 1000] loss: 0.05327\n",
      "Train Acc: 99 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 44, batch_cnt= 1250] loss: 0.04410\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 45, batch_cnt=  250] loss: 0.06940\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 45, batch_cnt=  500] loss: 0.08024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 45, batch_cnt=  750] loss: 0.06137\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 45, batch_cnt= 1000] loss: 0.03724\n",
      "Train Acc: 99 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 45, batch_cnt= 1250] loss: 0.06734\n",
      "Train Acc: 98 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 46, batch_cnt=  250] loss: 0.04079\n",
      "Train Acc: 99 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 46, batch_cnt=  500] loss: 0.05512\n",
      "Train Acc: 98 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 46, batch_cnt=  750] loss: 0.06070\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 46, batch_cnt= 1000] loss: 0.08520\n",
      "Train Acc: 98 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 46, batch_cnt= 1250] loss: 0.04966\n",
      "Train Acc: 99 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 47, batch_cnt=  250] loss: 0.03920\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 47, batch_cnt=  500] loss: 0.05994\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 47, batch_cnt=  750] loss: 0.04786\n",
      "Train Acc: 99 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 47, batch_cnt= 1000] loss: 0.09226\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 47, batch_cnt= 1250] loss: 0.05749\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 48, batch_cnt=  250] loss: 0.04633\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 48, batch_cnt=  500] loss: 0.04442\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 48, batch_cnt=  750] loss: 0.06002\n",
      "Train Acc: 94 %\n",
      "Accuracy: 79 %\n",
      "[epoch= 48, batch_cnt= 1000] loss: 0.10837\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 48, batch_cnt= 1250] loss: 0.05343\n",
      "Train Acc: 99 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 49, batch_cnt=  250] loss: 0.04377\n",
      "Train Acc: 99 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 49, batch_cnt=  500] loss: 0.05970\n",
      "Train Acc: 97 %\n",
      "Accuracy: 82 %\n",
      "[epoch= 49, batch_cnt=  750] loss: 0.08022\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 49, batch_cnt= 1000] loss: 0.07630\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 49, batch_cnt= 1250] loss: 0.05983\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 50, batch_cnt=  250] loss: 0.03366\n",
      "Train Acc: 98 %\n",
      "Accuracy: 84 %\n",
      "[epoch= 50, batch_cnt=  500] loss: 0.03966\n",
      "Train Acc: 99 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 50, batch_cnt=  750] loss: 0.04221\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 50, batch_cnt= 1000] loss: 0.04732\n",
      "Train Acc: 98 %\n",
      "Accuracy: 83 %\n",
      "[epoch= 50, batch_cnt= 1250] loss: 0.03856\n",
      "Train Acc: 99 %\n",
      "Accuracy: 84 %\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ed2f3031354b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\June\\Q56094077\\cvdl2020\\hw1\\models\\trainer\\trainer_kfold.py\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(self, width)\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch_tacc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_tacc_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mepoch_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\June\\Q56094077\\cvdl2020\\hw1\\models\\trainer\\trainer.py\u001b[0m in \u001b[0;36msaving\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;34m'loss'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         }\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "trainer.training(width=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "epoch_loss = np.array(trainer.epoch_loss).flatten()\n",
    "epoch_acc = np.array(trainer.epoch_acc).flatten()\n",
    "epoch_tacc = np.array(trainer.epoch_tacc).flatten()\n",
    "\n",
    "epoch_loss = list(epoch_loss)\n",
    "epoch_acc = list(epoch_acc)\n",
    "epoch_tacc = list(epoch_tacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('epoch.json', 'w') as fp:\n",
    "    epoch_info = {\n",
    "        'acc': epoch_acc,\n",
    "        'loss': epoch_loss,\n",
    "        'tacc': epoch_tacc\n",
    "    }\n",
    "    json.dump(epoch_info, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'model_stat': trainer.model.state_dict(),\n",
    "    'optimizer_stat': trainer.optimizer.state_dict(),\n",
    "    'loss': trainer.criterion.state_dict(),\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'vgg16_adma_batch32.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
